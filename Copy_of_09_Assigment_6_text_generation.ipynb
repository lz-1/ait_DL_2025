{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Copyright\n",
        "\n",
        "<PRE>\n",
        "Copyright (c) Bálint Gyires-Tóth - All Rights Reserved\n",
        "You may use and modify this code for research and development purpuses.\n",
        "Using this code for educational purposes (self-paced or instructor led) without the permission of the author is prohibited.\n",
        "</PRE>"
      ],
      "metadata": {
        "id": "CtuSrazlNYEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment: RNN text generation with your favorite book\n"
      ],
      "metadata": {
        "id": "vriXNd_nL2q6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "KFtxQWS1Ri6e"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Dataset\n",
        "- Download your favorite book from https://www.gutenberg.org/\n",
        "- Split into training (80%) and validation (20%)."
      ],
      "metadata": {
        "id": "Q5atve1sMH9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/gatsby.txt\", \"r\")\n",
        "book = f.read()\n",
        "\n",
        "train_size = int(0.8 * len(book))\n",
        "\n",
        "train = book[:train_size]\n",
        "val = book[train_size:]"
      ],
      "metadata": {
        "id": "QvKdt5EyMDug"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preprocessing\n",
        "- Convert text to lowercase.  \n",
        "- Remove punctuation (except basic sentence delimiters).  \n",
        "- Tokenize by words or characters (your choice).  \n",
        "- Build a vocabulary (map each unique word to an integer ID)."
      ],
      "metadata": {
        "id": "4eQMcyPgMLJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = book.lower()  # convert text to lowercase\n",
        "\n",
        "# remove punctuation\n",
        "remove = ''.join([char for char in string.punctuation if char not in \".!?\"])\n",
        "translator = str.maketrans('', '', remove)\n",
        "text = text.translate(translator)\n",
        "text = ' '.join(text.split())  # removes white space\n",
        "\n",
        "# tokenize\n",
        "vocab = sorted(set(list(text)))\n",
        "\n",
        "# vocabulary\n",
        "chars = tf.strings.unicode_split(text, input_encoding='UTF-8')\n",
        "chars_to_ids = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)\n",
        "ids = chars_to_ids(chars)\n",
        "\n",
        "# split preprocessed data into training and validation\n",
        "train = ids[:train_size]\n",
        "val = ids[train_size:]\n",
        "print(f\"Train size: {len(train)}\")\n",
        "print(f\"Validation size: {len(val)}\")"
      ],
      "metadata": {
        "id": "RvXRFVcbMLe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcfc1b14-4d74-414d-de9f-c4fc12585956"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 232061\n",
            "Validation size: 49744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Embedding Layer in Keras\n",
        "Below is a minimal example of defining an `Embedding` layer:\n",
        "```python\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    input_dim=vocab_size,     # size of the vocabulary\n",
        "    output_dim=128,           # embedding vector dimension\n",
        "    input_length=sequence_length\n",
        ")\n",
        "```\n",
        "- This layer transforms integer-encoded sequences (word IDs) into dense vector embeddings.\n",
        "\n",
        "- Feed these embeddings into your LSTM or GRU OR 1D CNN layer."
      ],
      "metadata": {
        "id": "jbTZs3OiMMNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sequence(text,sequence_length):\n",
        "  x = []; y = []\n",
        "  for i in range(0,len(text)-sequence_length,1):\n",
        "    x.append(text[i:i+sequence_length])\n",
        "    y.append(text[i+sequence_length])\n",
        "  return np.array(x), np.array(y)\n",
        "\n",
        "sequence_length = 100\n",
        "x_train, y_train = sequence(train,sequence_length)\n",
        "x_val, y_val = sequence(val,sequence_length)"
      ],
      "metadata": {
        "id": "B18qkTq5Tu5C"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape,y_train.shape)\n",
        "print(x_val.shape,y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPigwZPDXRCE",
        "outputId": "ba9d9c51-b87f-4cfd-a54d-ec9da3e675ab"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(231961, 100) (231961,)\n",
            "(49644, 100) (49644,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(chars_to_ids.get_vocabulary())\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "id": "OXCK40l6MRld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "391780ad-21d7-450b-f027-ee7f019ab0a2"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Model\n",
        "- Implement an LSTM or GRU or 1D CNN-based language model with:\n",
        "  - **The Embedding layer** as input.\n",
        "  - At least **one recurrent layer** (e.g., `LSTM(256)` or `GRU(256)` or your custom 1D CNN).\n",
        "  - A **Dense** output layer with **softmax** activation for word prediction.\n",
        "- Train for about **5–10 epochs** so it can finish in approximately **2 hours** on a standard machine.\n"
      ],
      "metadata": {
        "id": "qsXR4RZpMXMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "V3chtHMQT0qh"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(\n",
        "    input_dim=vocab_size,     # size of the vocabulary\n",
        "    output_dim=128,           # embedding vector dimension\n",
        "    input_length=sequence_length\n",
        "))\n",
        "model.add(LSTM(256, return_sequences=False))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "linweGaUMg0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b3aa19-a08f-4a59-b743-a3cf026a3def"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Training & Evaluation\n",
        "- **Monitor** the loss on both training and validation sets.\n",
        "- **Perplexity**: a common metric for language models.\n",
        "  - It is the exponent of the average negative log-likelihood.\n",
        "  - If your model outputs cross-entropy loss `H`, then `perplexity = e^H`.\n",
        "  - Try to keep the validation perplexity **under 50** if possible. If you have higher value (which is possible) try to draw conclusions, why doesn't it decrease to a lower value."
      ],
      "metadata": {
        "id": "Ggop4h4IMhMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network_history = model.fit(x_train, y_train,\n",
        "                            validation_data=(x_val, y_val),\n",
        "                            batch_size=128,\n",
        "                            epochs=5,\n",
        "                            verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyd6kmt3Y17H",
        "outputId": "85a0d7cb-f4c2-4522-8472-f2bfa2fefea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1813/1813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1785s\u001b[0m 983ms/step - accuracy: 0.3111 - loss: 2.3957 - val_accuracy: 0.4248 - val_loss: 2.0044\n",
            "Epoch 2/5\n",
            "\u001b[1m 822/1813\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m15:39\u001b[0m 948ms/step - accuracy: 0.4593 - loss: 1.8089"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Generation Criteria\n",
        "- After training, generate **two distinct text samples**, each at least **50 tokens**.\n",
        "- Use **different seed phrases** (e.g., “love is” vs. “time will”)."
      ],
      "metadata": {
        "id": "cbvbBOp3MfTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids_to_chars = tf.keras.layers.StringLookup(vocabulary=chars_to_ids.get_vocabulary(), invert=True)"
      ],
      "metadata": {
        "id": "M5J2wZiTmhg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_texts = [\"love is\", \"time will\"]\n",
        "for seed_text in seed_texts:\n",
        "  generated = seed_text\n",
        "  for _ in range(50):\n",
        "    input_chars = tf.strings.unicode_split(generated[-sequence_length:], 'UTF-8')\n",
        "    input_ids = chars_to_ids(input_chars)\n",
        "    input_ids = tf.expand_dims(input_ids, 0)\n",
        "    predicted = model.predict(input_ids,verbose=0)[0,-1]\n",
        "\n",
        "    predicted_char_index = np.random.choice(range(len(predicted)), p=predicted)\n",
        "    predicted_char = ids_to_chars([predicted_char_index]).numpy()[0].decode('utf-8')\n",
        "\n",
        "    generated += predicted_char\n",
        "\n",
        "  print(\"Generated with seed \", seed_text, \": \", generated)"
      ],
      "metadata": {
        "id": "1uHjn6aHMW5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n5CpdqF9MoPj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
