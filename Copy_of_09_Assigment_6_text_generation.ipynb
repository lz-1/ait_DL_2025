{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Copyright\n",
        "\n",
        "<PRE>\n",
        "Copyright (c) Bálint Gyires-Tóth - All Rights Reserved\n",
        "You may use and modify this code for research and development purpuses.\n",
        "Using this code for educational purposes (self-paced or instructor led) without the permission of the author is prohibited.\n",
        "</PRE>"
      ],
      "metadata": {
        "id": "CtuSrazlNYEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment: RNN text generation with your favorite book\n"
      ],
      "metadata": {
        "id": "vriXNd_nL2q6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "KFtxQWS1Ri6e"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Dataset\n",
        "- Download your favorite book from https://www.gutenberg.org/\n",
        "- Split into training (80%) and validation (20%)."
      ],
      "metadata": {
        "id": "Q5atve1sMH9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"/content/gatsby.txt\", \"r\")\n",
        "book = f.read()\n",
        "\n",
        "train_size = int(0.8 * len(book))\n",
        "\n",
        "train = book[:train_size]\n",
        "val = book[train_size:]"
      ],
      "metadata": {
        "id": "QvKdt5EyMDug"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Preprocessing\n",
        "- Convert text to lowercase.  \n",
        "- Remove punctuation (except basic sentence delimiters).  \n",
        "- Tokenize by words or characters (your choice).  \n",
        "- Build a vocabulary (map each unique word to an integer ID)."
      ],
      "metadata": {
        "id": "4eQMcyPgMLJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = book.lower()  # convert text to lowercase\n",
        "\n",
        "# remove punctuation\n",
        "remove = ''.join([char for char in string.punctuation if char not in \".!?\"])\n",
        "translator = str.maketrans('', '', remove)\n",
        "text = text.translate(translator)\n",
        "text = ' '.join(text.split())  # removes white space\n",
        "\n",
        "# tokenize\n",
        "vocab = sorted(set(list(text)))\n",
        "chars = tf.strings.unicode_split(text, input_encoding='UTF-8')\n",
        "\n",
        "# vocabulary\n",
        "chars_to_ids = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)\n",
        "ids = chars_to_ids(chars)\n",
        "\n",
        "# split preprocessed data into training and validation\n",
        "train = ids[:train_size]\n",
        "val = ids[train_size:]\n",
        "print(f\"Train size: {len(train)}\")\n",
        "print(f\"Validation size: {len(val)}\")"
      ],
      "metadata": {
        "id": "RvXRFVcbMLe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ae7d96-78ec-45c9-8313-31fb94afbac7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 232061\n",
            "Validation size: 49744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Embedding Layer in Keras\n",
        "Below is a minimal example of defining an `Embedding` layer:\n",
        "```python\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(\n",
        "    input_dim=vocab_size,     # size of the vocabulary\n",
        "    output_dim=128,           # embedding vector dimension\n",
        "    input_length=sequence_length\n",
        ")\n",
        "```\n",
        "- This layer transforms integer-encoded sequences (word IDs) into dense vector embeddings.\n",
        "\n",
        "- Feed these embeddings into your LSTM or GRU OR 1D CNN layer."
      ],
      "metadata": {
        "id": "jbTZs3OiMMNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function that splits sequences into first 99 characters (x) and last character (y)\n",
        "def sequence(text,sequence_length):\n",
        "  x = []; y = []\n",
        "  for i in range(0,len(text)-sequence_length,1):\n",
        "    x.append(text[i:i+sequence_length])\n",
        "    y.append(text[i+sequence_length])\n",
        "  return np.array(x), np.array(y)\n",
        "\n",
        "sequence_length = 100\n",
        "x_train, y_train = sequence(train,sequence_length)\n",
        "x_val, y_val = sequence(val,sequence_length)"
      ],
      "metadata": {
        "id": "B18qkTq5Tu5C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape,y_train.shape)\n",
        "print(x_val.shape,y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPigwZPDXRCE",
        "outputId": "680fe163-1890-4de6-c0a0-3aa09433cb1d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(231961, 100) (231961,)\n",
            "(49644, 100) (49644,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(chars_to_ids.get_vocabulary())\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "id": "OXCK40l6MRld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a0bdb9-7c74-4815-d20e-640c6d997241"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Model\n",
        "- Implement an LSTM or GRU or 1D CNN-based language model with:\n",
        "  - **The Embedding layer** as input.\n",
        "  - At least **one recurrent layer** (e.g., `LSTM(256)` or `GRU(256)` or your custom 1D CNN).\n",
        "  - A **Dense** output layer with **softmax** activation for word prediction.\n",
        "- Train for about **5–10 epochs** so it can finish in approximately **2 hours** on a standard machine.\n"
      ],
      "metadata": {
        "id": "qsXR4RZpMXMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "V3chtHMQT0qh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(\n",
        "    input_dim=vocab_size,     # size of the vocabulary\n",
        "    output_dim=128,           # embedding vector dimension\n",
        "    input_length=sequence_length\n",
        "))\n",
        "model.add(LSTM(256, return_sequences=False))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "linweGaUMg0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bad979d-e5f5-4ced-a1ff-75105201d1a1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Training & Evaluation\n",
        "- **Monitor** the loss on both training and validation sets.\n",
        "- **Perplexity**: a common metric for language models.\n",
        "  - It is the exponent of the average negative log-likelihood.\n",
        "  - If your model outputs cross-entropy loss `H`, then `perplexity = e^H`.\n",
        "  - Try to keep the validation perplexity **under 50** if possible. If you have higher value (which is possible) try to draw conclusions, why doesn't it decrease to a lower value."
      ],
      "metadata": {
        "id": "Ggop4h4IMhMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network_history = model.fit(x_train, y_train,\n",
        "                            validation_data=(x_val, y_val),\n",
        "                            batch_size=128,\n",
        "                            epochs=5,\n",
        "                            verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyd6kmt3Y17H",
        "outputId": "90cee5a6-5aca-45cc-9d13-2a8817a0c17b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1813/1813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1733s\u001b[0m 955ms/step - accuracy: 0.3126 - loss: 2.3910 - val_accuracy: 0.4168 - val_loss: 1.9929\n",
            "Epoch 2/5\n",
            "\u001b[1m1813/1813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1711s\u001b[0m 927ms/step - accuracy: 0.4679 - loss: 1.7696 - val_accuracy: 0.4690 - val_loss: 1.8139\n",
            "Epoch 3/5\n",
            "\u001b[1m1813/1813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1688s\u001b[0m 931ms/step - accuracy: 0.5180 - loss: 1.5888 - val_accuracy: 0.4925 - val_loss: 1.7222\n",
            "Epoch 4/5\n",
            "\u001b[1m1813/1813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1724s\u001b[0m 943ms/step - accuracy: 0.5500 - loss: 1.4758 - val_accuracy: 0.5095 - val_loss: 1.6712\n",
            "Epoch 5/5\n",
            "\u001b[1m1813/1813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1730s\u001b[0m 926ms/step - accuracy: 0.5692 - loss: 1.4040 - val_accuracy: 0.5212 - val_loss: 1.6390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss = network_history.history['val_loss'][-1]  # final val loss\n",
        "perplexity = np.exp(val_loss)\n",
        "print(f\"Validation Perplexity: {perplexity:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV121KnxPvnE",
        "outputId": "388422de-f91a-4726-8c35-45263b53669e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Perplexity: 5.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Generation Criteria\n",
        "- After training, generate **two distinct text samples**, each at least **50 tokens**.\n",
        "- Use **different seed phrases** (e.g., “love is” vs. “time will”)."
      ],
      "metadata": {
        "id": "cbvbBOp3MfTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert ids to chars function\n",
        "ids_to_chars = tf.keras.layers.StringLookup(vocabulary=chars_to_ids.get_vocabulary(), invert=True)"
      ],
      "metadata": {
        "id": "M5J2wZiTmhg-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_texts = [\"love is\", \"time will\"]\n",
        "for seed_text in seed_texts:\n",
        "  generated = seed_text\n",
        "  # generate 50 tokens\n",
        "  for _ in range(50):\n",
        "    input_chars = tf.strings.unicode_split(generated, 'UTF-8')  # converts to unicode chars\n",
        "    input_ids = chars_to_ids(input_chars)  # converts chars to ids\n",
        "    input_ids = tf.expand_dims(input_ids, 0)  # makes a batch of sequences for prediction\n",
        "    predictions = model.predict(input_ids,verbose=0)  # predict character\n",
        "    predicted = predictions[0]\n",
        "    predicted_char_index = np.random.choice(range(len(predicted)), p=predicted)  # select character based on prob\n",
        "    predicted_char = ids_to_chars([predicted_char_index]).numpy()[0].decode('utf-8')  # converts ids to char\n",
        "\n",
        "    generated += predicted_char  # concat to generated text\n",
        "\n",
        "  print(\"Generated with seed \\\"\", seed_text, \"\\\": \", generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukixK7FGNrzQ",
        "outputId": "3817202f-76ef-4bff-de13-bd342cafa71f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated with seed \" love is \":  love is we head at the car caliceuriam buling him a mils \n",
            "Generated with seed \" time will \":  time will and leaving lites a short he had tame will with a\n"
          ]
        }
      ]
    }
  ]
}
